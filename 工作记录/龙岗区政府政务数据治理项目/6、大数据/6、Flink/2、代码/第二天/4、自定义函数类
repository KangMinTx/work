package com.chenbk.day2

import org.apache.flink.api.common.functions.ReduceFunction
import org.apache.flink.api.java.functions.KeySelector
import org.apache.flink.streaming.api.scala._


object TransformTest {
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setParallelism(1)

    //1、从文件读取数据
    val inputStreamFormFlie:DataStream[String]=env.readTextFile("/Users/kang/Documents/Flink_2021/src/main/resources/sensor.txt")

    //基本转换操作
    val dataStream:DataStream[SensorReading]=inputStreamFormFlie.map(
      data=>{
        val dataArray=data.split(",")
        SensorReading(dataArray(0),dataArray(1).toLong,dataArray(2).toDouble)
      }
    )

    //2、分组滚动聚合
    val aggStream:DataStream[SensorReading]=dataStream
      .keyBy("id")
     .reduce(new MyRepuce)// 聚合出每个sensor的最大时间戳和最小温度值
    aggStream.print()
    env.execute()

  }

}

// 自定义函数类 ReduceFunction
class MyRepuce() extends ReduceFunction[SensorReading]{
  override def reduce(value1: SensorReading, value2: SensorReading): SensorReading = {
    SensorReading( value1.id, value1.timestamp.max(value2.timestamp), value1.temperature.min(value2.temperature) )
  }
}
